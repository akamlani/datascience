{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy  as np\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def read_data(filename):\n",
    "    lines = \"\"\n",
    "    with open(filename) as f:\n",
    "        lines = f.readlines()\n",
    "    return lines\n",
    "# read in data file\n",
    "d_lines = read_data(\"./drinking_network.inp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def parse_data(lines):\n",
    "    name = \"\"\n",
    "    data = {}\n",
    "    active_section_state = False\n",
    "    active_section_name  = \"\"\n",
    "    for content in lines:\n",
    "        content = content.strip().rstrip('\\r\\n')\n",
    "        if len(content) == 0: continue\n",
    "        # if this is content we filtered on, store away the key for processing and set the state\n",
    "        if content[0] == '[': \n",
    "            curr = data.get(content, [])\n",
    "            data[content] = curr\n",
    "            active_section_state = True\n",
    "            active_section_name  = content            \n",
    "        elif active_section_state and content[0] != ';':\n",
    "            curr = data.get(active_section_name, [])\n",
    "            line = content.split()\n",
    "            curr.append(line)\n",
    "            data[active_section_name] = curr\n",
    "    return data\n",
    "            \n",
    "sections_data = parse_data(d_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# filter the selected data based on the rules\n",
    "def filter_data(data, sections):\n",
    "    filtered = {}\n",
    "    for k,v, in data.items():\n",
    "        if k in sections:\n",
    "            if k == \"[JUNCTIONS]\" or k == \"[TANKS]\" or k == \"[RESERVOIRS]\":\n",
    "                for sample in v:\n",
    "                    if sample[0][:2] != \"NV\": \n",
    "                        curr = filtered.get(k, [])\n",
    "                        curr.append({\"ID\":sample[0]})\n",
    "                        filtered[k] = curr\n",
    "            elif k == \"[PIPES]\" or k == \"[VALVES]\":\n",
    "                for sample in v:\n",
    "                    curr = filtered.get(k, [])\n",
    "                    curr.append({\"ID\": sample[0], \"Node1\":sample[1], \"Node2\":sample[2] })\n",
    "                    filtered[k] = curr                \n",
    "    return filtered\n",
    "    \n",
    "d_sections = ['[JUNCTIONS]','[PIPES]','[VALVES]', '[TANKS]', '[RESERVOIRS]'] \n",
    "subset_data = filter_data(sections_data, d_sections)\n",
    "df_valves = pd.DataFrame(subset_data[\"[VALVES]\"])\n",
    "df_pipes  = pd.DataFrame(subset_data[\"[PIPES]\"])\n",
    "df_junctions = pd.DataFrame(subset_data[\"[JUNCTIONS]\"] )\n",
    "df_tanks = pd.DataFrame(subset_data[\"[TANKS]\"])\n",
    "df_reservoirs = pd.DataFrame(subset_data[\"[RESERVOIRS]\"])\n",
    "df_junctions = df_junctions.append(df_tanks)\n",
    "df_junctions = df_junctions.append(df_reservoirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def bfs_traversal(G, v, v_root, explore):\n",
    "    queue = []\n",
    "    visited = []\n",
    "    # Add the selected starting selection node to the queue\n",
    "    queue.append(v)\n",
    "    while len(queue) > 0:\n",
    "        # get the first element in the queue\n",
    "        item = queue.pop(0)\n",
    "        # mark the current process item as visited\n",
    "        if item not in visited: visited.append(item)\n",
    "        # add each of the adjacent neighbors to the queue\n",
    "        for k,v in G[item].items():\n",
    "            #print \"searching:\",k,v,v.label_id, v.explored\n",
    "            if k == v_root: continue\n",
    "            if k not in visited and not v.explored: queue.append(k)\n",
    "            if v.valve_existent and not v.explored: \n",
    "                v.explored = 1\n",
    "                G[k][item].explored =1                    \n",
    "                explore.append(v.label_id)\n",
    "                #explore.append((v.label_id, k))\n",
    "                #print 'valve founder:', item, k,v, v.label_id, v.explored, explore                \n",
    "                if v.explored: return visited, explore\n",
    "    return visited,explore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class AdjacentNeighbor(object):\n",
    "    def __init__(self, v_id, label_id, pattern, state):\n",
    "        self.pipe_existent  = False\n",
    "        self.valve_existent = False\n",
    "        self.vertex_id      = v_id\n",
    "        self.label_id       = label_id\n",
    "        self.root           = None\n",
    "        self.explored       = 0\n",
    "        self.assign(pattern, state)\n",
    "        \n",
    "    def assign(self, pattern, state):\n",
    "        if pattern == \"pipe\": self.pipe_existent = state\n",
    "        elif pattern == \"valve\": self.valve_existent = state\n",
    "\n",
    "def assign_to_dict(frame, key, data):\n",
    "    curr = frame.get(key, [])\n",
    "    curr.append(data)\n",
    "    frame[key] = curr\n",
    "    return frame \n",
    "\n",
    "def search_adj_neighbor(frame, key, vertex_id, label_id, pattern, state):\n",
    "    # get the current map for the vertex id\n",
    "    curr = frame.get(key, dict())        \n",
    "    adj  = curr.get(vertex_id, AdjacentNeighbor(vertex_id, label_id, pattern, state))\n",
    "    adj.assign(pattern, state)\n",
    "    curr[vertex_id] = adj\n",
    "    frame[key] = curr\n",
    "    return frame\n",
    "    \n",
    "def create_adjacent_neighbors(junctions, pipes, valves):\n",
    "    # iterate through junction list, and find neighbors based on pipes and valves\n",
    "    neighbors = {}\n",
    "    for index,row in junctions.iterrows(): \n",
    "        pipe_node_neighbor  = pipes.loc[ (pipes.Node1 == row.ID) | (pipes.Node2 == row.ID)]\n",
    "        valve_node_neighbor = valves.loc[ (valves.Node1 == row.ID) | (valves.Node2 == row.ID)]\n",
    "        for index,node_i in pipe_node_neighbor.iterrows():\n",
    "            nx =  filter(lambda x: x != row.ID, [node_i.Node1,node_i.Node2])[0]\n",
    "            neighbors = search_adj_neighbor(neighbors, row.ID, nx, node_i.ID, \"pipe\", True)            \n",
    "        for index,node_i in valve_node_neighbor.iterrows():\n",
    "            nx =  filter(lambda x: x != row.ID, [node_i.Node1,node_i.Node2])[0]\n",
    "            neighbors = search_adj_neighbor(neighbors, row.ID, nx, node_i.ID, \"valve\", True)\n",
    "    return neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create a sparse neighbor list\n",
    "# iterate and find all vertices that matched together (Pipe: Set(Valves))\n",
    "def create_pipe_valve_association(neighbors, pipes, valves, pipe_id):\n",
    "    pipeline  = {}\n",
    "    df_pipes_filtered = pipes[pipes[\"ID\"].isin(pipe_id)]\n",
    "    for index,row in df_pipes_filtered.iterrows():\n",
    "    #for index,row in pipes.iterrows():\n",
    "        # For a particular pipeline and corresponding nodes, find all existing valves\n",
    "        # Default Case: If we find valves on each side of the junction - we are done\n",
    "        valve_node1 = valves.loc[ (valves.Node1 == row.Node1) | (valves.Node2 == row.Node1)].ID.values\n",
    "        valve_node2 = valves.loc[ (valves.Node1 == row.Node2) | (valves.Node2 == row.Node2)].ID.values\n",
    "        valve_pipeline = list(valve_node1) + list(valve_node2)\n",
    "        pipeline[row.ID] = set(valve_pipeline)\n",
    "\n",
    "        # when haven't found a valve on each side of a junction point for the respective pipeline, walk the valves\n",
    "        # handles the case where we had pipes on each side of the junction, and no direct valves\n",
    "        # handles the case where we only need to one particular junction from this pipeline\n",
    "        # there may exist a termination node where we don't need to handle a valve (will be noted in neighbor list)\n",
    "        if len(valve_pipeline) < 2:\n",
    "            # we drop the search from the valves we have already found from our search\n",
    "            connpipe_node1 = pipes.loc[ (pipes.Node1 == row.Node1) | (pipes.Node2 == row.Node1) ] \n",
    "            connpipe_node1_sub = connpipe_node1.drop(index)\n",
    "            connpipe_node2 = pipes.loc[ (pipes.Node1 == row.Node2) | (pipes.Node2 == row.Node2) ]\n",
    "            connpipe_node2_sub = connpipe_node2.drop(index)\n",
    "            # walk each of these pipes from the vertice in adjacency table \n",
    "            if len(connpipe_node1_sub):\n",
    "                explored = []\n",
    "                for k,v in adj_neighbors[row.Node1].items(): \n",
    "                    if v.pipe_existent: _, explored = bfs_traversal(neighbors, v.vertex_id, row.Node1, explored )\n",
    "                for i in explored: pipeline[row.ID].add(i)\n",
    "            if len(connpipe_node2_sub):\n",
    "                explored = []\n",
    "                for k,v in adj_neighbors[row.Node2].items(): \n",
    "                    if v.pipe_existent: _, explored = bfs_traversal(neighbors, v.vertex_id, row.Node2, explored )\n",
    "                for i in explored: pipeline[row.ID].add(i)\n",
    "    return pipeline\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipe Queries: 14T1095\n",
      "Pipe Queries: 14T1093\n",
      "Pipe Queries: 14T87f\n",
      "Pipe Queries: 14Tf9f\n"
     ]
    }
   ],
   "source": [
    "# Parse input file and create valve association\n",
    "# pipe_input = list( df_pipes.ID[:count].values )\n",
    "cmd_args = read_data(\"./drinking_network_input.txt\")\n",
    "sections_data = parse_data(cmd_args)\n",
    "pipe_selections = sections_data['[Pipe Queries]']\n",
    "pipe_selections = [i[0] for i in pipe_selections if i[0]!= '#']\n",
    "for i in pipe_selections: print \"Pipe Queries: {0}\".format(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Execute pipe association\n",
    "adj_neighbors = create_adjacent_neighbors(df_junctions, df_pipes, df_valves)\n",
    "pipeline_assoc = create_pipe_valve_association(adj_neighbors, df_pipes, df_valves, pipe_selections)\n",
    "for k,v in adj_neighbors.items(): del adj_neighbors[k]\n",
    "del adj_neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pipe</th>\n",
       "      <th>valves</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>query</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14Tf9f</td>\n",
       "      <td>V6eb48, V6ef49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14T1095</td>\n",
       "      <td>V6eacb, DG125-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14T1093</td>\n",
       "      <td>V6eaa9, V6eac4, V6eb38, V6eac6, V6eac3, DJ127-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14T87f</td>\n",
       "      <td>V6eb69, V6eab2, V6eb70, V6ead1, BG17Q1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          pipe                                            valves\n",
       "query                                                           \n",
       "0       14Tf9f                                    V6eb48, V6ef49\n",
       "1      14T1095                                  V6eacb, DG125-03\n",
       "2      14T1093  V6eaa9, V6eac4, V6eb38, V6eac6, V6eac3, DJ127-03\n",
       "3       14T87f            V6eb69, V6eab2, V6eb70, V6ead1, BG17Q1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# output based on selection of pipe_filter\n",
    "pd.set_option('display.max_colwidth', 1000)\n",
    "df_pipeline = pd.DataFrame(pipeline_assoc.items(), columns = ['pipe', 'valves'])\n",
    "df_pipeline.valves = df_pipeline.valves.apply(lambda x: \", \".join(x) )\n",
    "df_pipeline.index.name = \"query\"\n",
    "df_pipeline.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing output to file: drinking_network_output.txt\n"
     ]
    }
   ],
   "source": [
    "# write output to file\n",
    "# log results to output file\n",
    "print \"Writing output to file: drinking_network_output.txt\"\n",
    "header = list(df_pipeline.columns)\n",
    "lines = [str(df_pipeline.ix[i,'pipe']) + \"\\t\\t\" + str(df_pipeline.ix[i,'valves']) for i,v in df_pipeline.iterrows()]\n",
    "lines.insert(0, header)\n",
    "output = \"\"\n",
    "for l in lines: output += str(l) + \"\\r\\n\"\n",
    "with open(\"./drinking_network_output.txt\", 'w') as f: f.write(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "######General Analysis\n",
    "- Pipeline Association : O(|V| + |E|), where E is for each adjacent neighbor of a given vertex v\n",
    "- BFS from pipeline association contributes O(|V| + |E|)\n",
    "- Each vertex for the Adacent list contributes memory, the size of AdjacentNeighbor class\n",
    "- Optimization in the Adjacency and usage of it can be made such that duplicates are not stored, and the corresponding neighbor entry is not duplicated, and only stored in one place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
